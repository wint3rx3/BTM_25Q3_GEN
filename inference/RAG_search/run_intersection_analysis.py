"""
RAG ê²€ìƒ‰ ë°©ë²•ë“¤ì˜ êµì§‘í•© ë¶„ì„ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
ì„¸ ê°€ì§€ ê²€ìƒ‰ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•˜ê³  êµì§‘í•©ì„ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import os
import sys
import pandas as pd
from pathlib import Path

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

from unified_csv_utils import analyze_intersection, print_intersection_summary, create_unified_csv


def ensure_unified_csvs():
    """
    ê° ë°©ë²•ì˜ ê²°ê³¼ë¥¼ í†µì¼ëœ í˜•íƒœë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
    """
    methods = [
        ('method1', 'result/RAG_result/method1_results.csv', 'result/RAG_result/method1_unified.csv'),
        ('method2', 'result/RAG_result/method2_results.csv', 'result/RAG_result/method2_unified.csv'),
        ('method3', 'result/RAG_result/method3_results.csv', 'result/RAG_result/method3_unified.csv')
    ]
    
    unified_files = []
    
    for method_name, original_file, unified_file in methods:
        if os.path.exists(original_file) and not os.path.exists(unified_file):
            try:
                print(f"ğŸ”„ {method_name} ê²°ê³¼ë¥¼ í†µì¼ëœ í˜•íƒœë¡œ ë³€í™˜ ì¤‘...")
                df = pd.read_csv(original_file)
                
                # ê° ë°©ë²•ë³„ë¡œ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë§¤í•‘
                if method_name == 'method1':
                    # Method 1ì€ ì´ë¯¸ í†µì¼ëœ í˜•íƒœì—¬ì•¼ í•¨
                    if 'query_id' in df.columns:
                        create_unified_csv(df, method_name, unified_file)
                    else:
                        print(f"âš ï¸ {method_name}: í†µì¼ëœ í˜•íƒœê°€ ì•„ë‹Œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ìˆ˜ë™ ë³€í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                
                elif method_name == 'method2':
                    # Method 2ë„ ì´ë¯¸ í†µì¼ëœ í˜•íƒœì—¬ì•¼ í•¨
                    if 'query_id' in df.columns:
                        create_unified_csv(df, method_name, unified_file)
                    else:
                        print(f"âš ï¸ {method_name}: í†µì¼ëœ í˜•íƒœê°€ ì•„ë‹Œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ìˆ˜ë™ ë³€í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                
                elif method_name == 'method3':
                    # Method 3ë„ ì´ë¯¸ í†µì¼ëœ í˜•íƒœì—¬ì•¼ í•¨
                    if 'query_id' in df.columns:
                        create_unified_csv(df, method_name, unified_file)
                    else:
                        print(f"âš ï¸ {method_name}: í†µì¼ëœ í˜•íƒœê°€ ì•„ë‹Œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ìˆ˜ë™ ë³€í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                
            except Exception as e:
                print(f"âŒ {method_name} ë³€í™˜ ì‹¤íŒ¨: {e}")
        
        if os.path.exists(unified_file):
            unified_files.append(unified_file)
        elif os.path.exists(original_file):
            # í†µì¼ëœ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì›ë³¸ íŒŒì¼ ì‚¬ìš©
            unified_files.append(original_file)
    
    return unified_files


def main():
    """
    êµì§‘í•© ë¶„ì„ ë©”ì¸ í•¨ìˆ˜
    """
    print("ğŸš€ RAG ê²€ìƒ‰ ë°©ë²• êµì§‘í•© ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print()
    
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ í™•ì¸
    result_dir = Path("result/RAG_result")
    if not result_dir.exists():
        print("âŒ result/RAG_result ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € ê° RAG ê²€ìƒ‰ ë°©ë²•ì„ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return
    
    # í†µì¼ëœ í˜•íƒœì˜ CSV íŒŒì¼ ì¤€ë¹„
    unified_files = ensure_unified_csvs()
    
    if len(unified_files) < 2:
        print("âŒ ë¹„êµí•  ìˆ˜ ìˆëŠ” ê²°ê³¼ íŒŒì¼ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print(f"ì°¾ì€ íŒŒì¼: {unified_files}")
        return
    
    print(f"ğŸ“‚ ë¶„ì„í•  íŒŒì¼ë“¤: {len(unified_files)}ê°œ")
    for file in unified_files:
        print(f"  - {file}")
    print()
    
    # êµì§‘í•© ë¶„ì„ ìˆ˜í–‰
    try:
        analysis_results = analyze_intersection(
            unified_files, 
            'result/RAG_result/intersection_analysis.json'
        )
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print_intersection_summary(analysis_results)
        
        # ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë„ ì €ì¥
        save_detailed_analysis(analysis_results, 'result/RAG_result/intersection_detailed.txt')
        
        print("\nâœ… êµì§‘í•© ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸ“ ê²°ê³¼ íŒŒì¼:")
        print("  - result/RAG_result/intersection_analysis.json (ì „ì²´ ë¶„ì„ ê²°ê³¼)")
        print("  - result/RAG_result/intersection_detailed.txt (ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ)")
        
    except Exception as e:
        print(f"âŒ êµì§‘í•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


def save_detailed_analysis(analysis_results, output_path):
    """
    ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        analysis_results (dict): analyze_intersectionì˜ ê²°ê³¼
        output_path (str): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("RAG ê²€ìƒ‰ ë°©ë²•ë³„ êµì§‘í•© ë¶„ì„ ìƒì„¸ ë³´ê³ ì„œ\n")
        f.write("=" * 80 + "\n\n")
        
        # ê¸°ë³¸ ì •ë³´
        f.write(f"ë¶„ì„ ì¼ì‹œ: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ì´ ì¿¼ë¦¬ ìˆ˜: {analysis_results['total_queries']}\n")
        f.write(f"ë¶„ì„ ë°©ë²• ìˆ˜: {len(analysis_results['method_coverage'])}\n\n")
        
        # ë°©ë²•ë³„ ì„±ëŠ¥
        f.write("1. ë°©ë²•ë³„ ê²€ìƒ‰ ì„±ëŠ¥\n")
        f.write("-" * 40 + "\n")
        for method, stats in analysis_results['method_coverage'].items():
            f.write(f"\n[{method}]\n")
            f.write(f"  ê³ ìœ  ë¬¸ì„œ ìˆ˜: {stats['unique_documents']}\n")
            f.write(f"  ì´ ê²€ìƒ‰ ê²°ê³¼: {stats['total_retrievals']}\n")
            f.write(f"  ê²°ê³¼ê°€ ìˆëŠ” ì¿¼ë¦¬: {stats['queries_with_results']}\n")
            coverage_rate = stats['queries_with_results'] / analysis_results['total_queries'] * 100
            f.write(f"  ì»¤ë²„ë¦¬ì§€ ë¹„ìœ¨: {coverage_rate:.1f}%\n")
        
        # ìŒë³„ ìœ ì‚¬ì„±
        f.write(f"\n\n2. ë°©ë²• ê°„ ìœ ì‚¬ì„± ë¶„ì„\n")
        f.write("-" * 40 + "\n")
        for pair_name, stats in analysis_results['pairwise_intersections'].items():
            f.write(f"\n[{pair_name}]\n")
            f.write(f"  í‰ê·  Jaccard ìœ ì‚¬ë„: {stats['average_jaccard']:.3f}\n")
            f.write(f"  í‰ê·  êµì§‘í•© í¬ê¸°: {stats['average_intersection_size']:.1f}\n")
            f.write(f"  êµì§‘í•©ì´ ìˆëŠ” ì¿¼ë¦¬: {stats['queries_with_intersection']}\n")
            intersection_rate = stats['queries_with_intersection'] / analysis_results['total_queries'] * 100
            f.write(f"  êµì§‘í•© ë¹„ìœ¨: {intersection_rate:.1f}%\n")
        
        # ì „ì²´ êµì§‘í•© í†µê³„
        if analysis_results['complete_intersection']:
            f.write(f"\n\n3. ì „ì²´ êµì§‘í•© í†µê³„\n")
            f.write("-" * 40 + "\n")
            
            intersection_sizes = [q['intersection_size'] for q in analysis_results['complete_intersection']]
            union_sizes = [q['union_size'] for q in analysis_results['union_coverage']]
            
            queries_with_intersection = len([s for s in intersection_sizes if s > 0])
            f.write(f"  êµì§‘í•©ì´ ìˆëŠ” ì¿¼ë¦¬: {queries_with_intersection}\n")
            f.write(f"  êµì§‘í•© ë¹„ìœ¨: {queries_with_intersection / analysis_results['total_queries'] * 100:.1f}%\n")
            f.write(f"  í‰ê·  êµì§‘í•© í¬ê¸°: {sum(intersection_sizes) / len(intersection_sizes):.1f}\n")
            f.write(f"  í‰ê·  í•©ì§‘í•© í¬ê¸°: {sum(union_sizes) / len(union_sizes):.1f}\n")
            f.write(f"  ìµœëŒ€ êµì§‘í•© í¬ê¸°: {max(intersection_sizes)}\n")
            f.write(f"  ìµœëŒ€ í•©ì§‘í•© í¬ê¸°: {max(union_sizes)}\n")
            
            # êµì§‘í•© í¬ê¸°ë³„ ë¶„í¬
            from collections import Counter
            intersection_dist = Counter(intersection_sizes)
            f.write(f"\n  êµì§‘í•© í¬ê¸°ë³„ ë¶„í¬:\n")
            for size in sorted(intersection_dist.keys()):
                count = intersection_dist[size]
                f.write(f"    í¬ê¸° {size}: {count}ê°œ ì¿¼ë¦¬\n")
        
        # ì¿¼ë¦¬ë³„ ìƒì„¸ ë¶„ì„ (ì²˜ìŒ 10ê°œë§Œ)
        f.write(f"\n\n4. ì¿¼ë¦¬ë³„ ìƒì„¸ ë¶„ì„ (ìƒìœ„ 10ê°œ ì¿¼ë¦¬)\n")
        f.write("-" * 40 + "\n")
        
        if analysis_results['complete_intersection']:
            for i, query_analysis in enumerate(analysis_results['complete_intersection'][:10]):
                f.write(f"\nì¿¼ë¦¬ {query_analysis['query_id']}:\n")
                f.write(f"  êµì§‘í•© í¬ê¸°: {query_analysis['intersection_size']}\n")
                f.write(f"  í•©ì§‘í•© í¬ê¸°: {query_analysis['union_size']}\n")
                if query_analysis['intersection_docs']:
                    f.write(f"  ê³µí†µ ë¬¸ì„œ ID: {query_analysis['intersection_docs'][:5]}{'...' if len(query_analysis['intersection_docs']) > 5 else ''}\n")
        
        f.write(f"\n\n" + "=" * 80 + "\n")
        f.write("ë¶„ì„ ì™„ë£Œ\n")
        f.write("=" * 80 + "\n")


if __name__ == "__main__":
    main()

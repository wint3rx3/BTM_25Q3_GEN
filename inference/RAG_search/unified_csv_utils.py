"""
í†µì¼ëœ CSV í˜•íƒœë¡œ RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
"""

import pandas as pd
import numpy as np
from typing import List, Dict, Any


def create_unified_csv(results_df: pd.DataFrame, method_name: str, output_path: str) -> None:
    """
    RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µì¼ëœ í˜•íƒœì˜ CSVë¡œ ì €ì¥
    
    Args:
        results_df (pd.DataFrame): ê²€ìƒ‰ ê²°ê³¼ DataFrame
        method_name (str): ê²€ìƒ‰ ë°©ë²•ëª… (method1, method2, method3)
        output_path (str): ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ
    """
    
    # í†µì¼ëœ ì»¬ëŸ¼ëª… í™•ì¸
    required_columns = ['query_id', 'input_text', 'retrieved_indices', 'retrieved_scores', 'method']
    
    # í•„ìˆ˜ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
    missing_columns = [col for col in required_columns if col not in results_df.columns]
    if missing_columns:
        raise ValueError(f"Missing required columns: {missing_columns}")
    
    # í†µì¼ëœ í˜•íƒœë¡œ ì¬ì •ë ¬
    unified_df = results_df[required_columns].copy()
    
    # ì¶”ê°€ í†µê³„ ì •ë³´ ì»¬ëŸ¼ ìƒì„±
    unified_df['num_results'] = unified_df['retrieved_indices'].apply(len)
    unified_df['max_score'] = unified_df['retrieved_scores'].apply(
        lambda x: max(x) if x else 0.0
    )
    unified_df['min_score'] = unified_df['retrieved_scores'].apply(
        lambda x: min(x) if x else 0.0
    )
    unified_df['avg_score'] = unified_df['retrieved_scores'].apply(
        lambda x: np.mean(x) if x else 0.0
    )
    
    # CSVë¡œ ì €ì¥
    unified_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"âœ… í†µì¼ëœ í˜•íƒœì˜ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")


def analyze_intersection(csv_paths: List[str], output_path: str = None) -> Dict[str, Any]:
    """
    ì—¬ëŸ¬ RAG ê²€ìƒ‰ ë°©ë²•ì˜ ê²°ê³¼ì—ì„œ êµì§‘í•© ë¶„ì„
    
    Args:
        csv_paths (List[str]): ê° ë°©ë²•ì˜ CSV íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        output_path (str, optional): êµì§‘í•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        
    Returns:
        Dict[str, Any]: êµì§‘í•© ë¶„ì„ ê²°ê³¼
    """
    
    # ê° ë°©ë²•ì˜ ê²°ê³¼ ë¡œë“œ
    method_results = {}
    for csv_path in csv_paths:
        df = pd.read_csv(csv_path)
        method_name = df['method'].iloc[0] if 'method' in df.columns else csv_path
        method_results[method_name] = df
    
    analysis_results = {
        'total_queries': 0,
        'method_coverage': {},
        'pairwise_intersections': {},
        'complete_intersection': [],
        'union_coverage': []
    }
    
    if not method_results:
        return analysis_results
    
    # ì´ ì¿¼ë¦¬ ìˆ˜ (ëª¨ë“  ë°©ë²•ì´ ë™ì¼í•´ì•¼ í•¨)
    query_counts = [len(df) for df in method_results.values()]
    if len(set(query_counts)) > 1:
        print("âš ï¸ ê²½ê³ : ë°©ë²•ë³„ ì¿¼ë¦¬ ìˆ˜ê°€ ë‹¤ë¦…ë‹ˆë‹¤.")
    
    analysis_results['total_queries'] = max(query_counts) if query_counts else 0
    
    # ê° ë°©ë²•ë³„ ì»¤ë²„ë¦¬ì§€ ë¶„ì„
    for method_name, df in method_results.items():
        retrieved_docs = []
        for _, row in df.iterrows():
            if row['retrieved_indices']:  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°
                retrieved_docs.extend(eval(row['retrieved_indices']) if isinstance(row['retrieved_indices'], str) else row['retrieved_indices'])
        
        unique_docs = set(retrieved_docs)
        analysis_results['method_coverage'][method_name] = {
            'unique_documents': len(unique_docs),
            'total_retrievals': len(retrieved_docs),
            'queries_with_results': len([1 for _, row in df.iterrows() if row['retrieved_indices'] and len(eval(row['retrieved_indices']) if isinstance(row['retrieved_indices'], str) else row['retrieved_indices']) > 0])
        }
    
    # ìŒë³„ êµì§‘í•© ë¶„ì„
    method_names = list(method_results.keys())
    for i in range(len(method_names)):
        for j in range(i+1, len(method_names)):
            method1, method2 = method_names[i], method_names[j]
            
            # ê° ì¿¼ë¦¬ë³„ë¡œ êµì§‘í•© ê³„ì‚°
            query_intersections = []
            for query_id in range(min(len(method_results[method1]), len(method_results[method2]))):
                docs1 = method_results[method1].iloc[query_id]['retrieved_indices']
                docs2 = method_results[method2].iloc[query_id]['retrieved_indices']
                
                # ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
                if isinstance(docs1, str):
                    docs1 = eval(docs1) if docs1.strip() else []
                if isinstance(docs2, str):
                    docs2 = eval(docs2) if docs2.strip() else []
                
                intersection = set(docs1) & set(docs2)
                union = set(docs1) | set(docs2)
                
                query_intersections.append({
                    'query_id': query_id,
                    'intersection_size': len(intersection),
                    'union_size': len(union),
                    'jaccard_similarity': len(intersection) / len(union) if union else 0.0,
                    'method1_size': len(docs1),
                    'method2_size': len(docs2)
                })
            
            analysis_results['pairwise_intersections'][f"{method1}_vs_{method2}"] = {
                'query_level_analysis': query_intersections,
                'average_jaccard': np.mean([q['jaccard_similarity'] for q in query_intersections]),
                'average_intersection_size': np.mean([q['intersection_size'] for q in query_intersections]),
                'queries_with_intersection': len([q for q in query_intersections if q['intersection_size'] > 0])
            }
    
    # ì „ì²´ êµì§‘í•© (ëª¨ë“  ë°©ë²•ì—ì„œ ê³µí†µìœ¼ë¡œ ê²€ìƒ‰ëœ ë¬¸ì„œ)
    if len(method_names) >= 2:
        for query_id in range(analysis_results['total_queries']):
            query_docs = []
            for method_name in method_names:
                if query_id < len(method_results[method_name]):
                    docs = method_results[method_name].iloc[query_id]['retrieved_indices']
                    if isinstance(docs, str):
                        docs = eval(docs) if docs.strip() else []
                    query_docs.append(set(docs))
            
            if query_docs:
                complete_intersection = set.intersection(*query_docs) if query_docs else set()
                union_docs = set.union(*query_docs) if query_docs else set()
                
                analysis_results['complete_intersection'].append({
                    'query_id': query_id,
                    'intersection_size': len(complete_intersection),
                    'union_size': len(union_docs),
                    'intersection_docs': list(complete_intersection)
                })
                
                analysis_results['union_coverage'].append({
                    'query_id': query_id,
                    'union_size': len(union_docs),
                    'union_docs': list(union_docs)
                })
    
    # ê²°ê³¼ ì €ì¥
    if output_path:
        import json
        with open(output_path, 'w', encoding='utf-8') as f:
            # JSON ì§ë ¬í™”ë¥¼ ìœ„í•´ setì„ listë¡œ ë³€í™˜
            serializable_results = analysis_results.copy()
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        print(f"âœ… êµì§‘í•© ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
    
    return analysis_results


def print_intersection_summary(analysis_results: Dict[str, Any]) -> None:
    """
    êµì§‘í•© ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    
    Args:
        analysis_results (Dict[str, Any]): analyze_intersectionì˜ ê²°ê³¼
    """
    print("=" * 50)
    print("ğŸ“Š RAG ê²€ìƒ‰ ë°©ë²•ë³„ êµì§‘í•© ë¶„ì„ ê²°ê³¼")
    print("=" * 50)
    
    print(f"ì´ ì¿¼ë¦¬ ìˆ˜: {analysis_results['total_queries']}")
    print()
    
    # ë°©ë²•ë³„ ì»¤ë²„ë¦¬ì§€
    print("ğŸ” ë°©ë²•ë³„ ê²€ìƒ‰ ì„±ëŠ¥:")
    for method, stats in analysis_results['method_coverage'].items():
        print(f"  {method}:")
        print(f"    - ê³ ìœ  ë¬¸ì„œ ìˆ˜: {stats['unique_documents']}")
        print(f"    - ì´ ê²€ìƒ‰ ê²°ê³¼: {stats['total_retrievals']}")
        print(f"    - ê²°ê³¼ê°€ ìˆëŠ” ì¿¼ë¦¬: {stats['queries_with_results']}")
    print()
    
    # ìŒë³„ êµì§‘í•©
    print("ğŸ¤ ë°©ë²• ê°„ ìœ ì‚¬ì„±:")
    for pair_name, stats in analysis_results['pairwise_intersections'].items():
        print(f"  {pair_name}:")
        print(f"    - í‰ê·  Jaccard ìœ ì‚¬ë„: {stats['average_jaccard']:.3f}")
        print(f"    - í‰ê·  êµì§‘í•© í¬ê¸°: {stats['average_intersection_size']:.1f}")
        print(f"    - êµì§‘í•©ì´ ìˆëŠ” ì¿¼ë¦¬: {stats['queries_with_intersection']}")
    print()
    
    # ì „ì²´ êµì§‘í•© í†µê³„
    if analysis_results['complete_intersection']:
        intersection_sizes = [q['intersection_size'] for q in analysis_results['complete_intersection']]
        union_sizes = [q['union_size'] for q in analysis_results['union_coverage']]
        
        print("ğŸ¯ ì „ì²´ êµì§‘í•© í†µê³„:")
        print(f"  - êµì§‘í•©ì´ ìˆëŠ” ì¿¼ë¦¬: {len([s for s in intersection_sizes if s > 0])}")
        print(f"  - í‰ê·  êµì§‘í•© í¬ê¸°: {np.mean(intersection_sizes):.1f}")
        print(f"  - í‰ê·  í•©ì§‘í•© í¬ê¸°: {np.mean(union_sizes):.1f}")
        print(f"  - ìµœëŒ€ êµì§‘í•© í¬ê¸°: {max(intersection_sizes)}")
    
    print("=" * 50)


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # êµì§‘í•© ë¶„ì„ ì˜ˆì‹œ
    csv_files = [
        'result/method1_results.csv',
        'result/method2_results.csv', 
        'result/method3_results.csv'
    ]
    
    try:
        results = analyze_intersection(csv_files, 'result/intersection_analysis.json')
        print_intersection_summary(results)
    except Exception as e:
        print(f"âŒ êµì§‘í•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
